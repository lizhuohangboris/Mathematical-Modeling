VAR：

```python
# 检查数据是否平稳
def adfuller_test(series, signif=0.05):
    result = adfuller(series)
    labels = ['ADF Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used']
    for value, label in zip(result, labels):
        print(label + " : " + str(value))
    if result[1] <= signif:
        print("强证据拒绝原假设，数据平稳")
        return True
    else:
        print("弱证据接受原假设，数据非平稳")
        return False

# 检查每个列的平稳性
for col in data.columns[1:]:
    print("列名：" + col)
    adfuller_test(data[col])
    print("\n")

# 创建VAR模型并拟合数据
model = VAR(data)
model_fit = model.fit()

# 检查模型阶数
model_order = model_fit.k_ar
print('VAR模型阶数:', model_order)

# 执行预测
forecast = model_fit.forecast(model_fit.endog, steps=38)
forecast_df = pd.DataFrame(forecast, index=range(data.shape[0], data.shape[0]+38), columns=data.columns)

# 输出预测结果
print(forecast_df)

# 保存预测结果为Excel文件
output_path = 'forecast_results.xlsx'
forecast_df.to_excel(output_path, index=False)
print(f'预测结果已保存为 {output_path}')
```

多元线性回归：

```python
# 使用模型预测未来年份的二氧化碳排放量
future_X = future_data.drop(columns=['年份'])
future_predictions = model.predict(future_X)

# 将预测结果存储在DataFrame中
future_df = pd.DataFrame({'年份': future_years, '预测二氧化碳排放量（百万吨）': future_predictions})

# 显示未来预测结果的表格
print("未来二氧化碳排放量预测结果：")
print(future_df)
```

LSTM：

```python
training_data = pd.read_excel(training_data_path)
prediction_data = pd.read_excel(prediction_data_path)

# 设置索引为'年份'
training_data.set_index('年份', inplace=True)
prediction_data.set_index('年份', inplace=True)

# 选择特征和目标
features = ['GDP（十亿）', '人口（百万人）', '钢铁产量（千吨）', '水泥（百万吨）', '民用汽车数量（千辆）', '煤炭消耗量（百万吨）', '原油消耗量', '天然气消耗量', '新能源消耗量']
target = '二氧化碳排放量（百万吨）'

# 组合特征和目标进行标准化
training_data_combined = training_data[features + [target]]
prediction_data_combined = prediction_data[features]

# 标准化特征
feature_scaler = MinMaxScaler()
scaled_training_features = feature_scaler.fit_transform(training_data[features])
scaled_prediction_features = feature_scaler.transform(prediction_data[features])

# 标准化目标
target_scaler = MinMaxScaler()
scaled_training_target = target_scaler.fit_transform(training_data[[target]])

# 准备LSTM模型的数据
def create_dataset(features, target, time_step=1):
    X, Y = [], []
    for i in range(len(features) - time_step - 1):
        a = features[i:(i + time_step)]
        X.append(a)
        Y.append(target[i + time_step])
    return np.array(X), np.array(Y)

time_step = 5
X_train, y_train = create_dataset(scaled_training_features, scaled_training_target, time_step)

# 将输入重塑为 [样本数, 时间步, 特征数]
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], len(features))

# 准备预测数据
X_predict = []
for i in range(len(scaled_prediction_features) - time_step):
    X_predict.append(scaled_prediction_features[i:(i + time_step)])
X_predict = np.array(X_predict)

# 创建并训练LSTM网络
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(time_step, len(features))))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(1))
model.compile(optimizer='adam', loss='mean_squared_error')

model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=2)

# 进行预测
train_predict = model.predict(X_train)
future_predict = model.predict(X_predict)

# 反标准化预测结果
train_predict = target_scaler.inverse_transform(train_predict)
future_predict = target_scaler.inverse_transform(future_predict)

# 将预测结果添加到prediction_data中
prediction_data['二氧化碳排放量（百万吨）'] = np.nan
prediction_data.iloc[-len(future_predict):, prediction_data.columns.get_loc('二氧化碳排放量（百万吨）')] = future_predict.flatten()
```

