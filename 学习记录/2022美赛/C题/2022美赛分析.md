## é¢˜ç›®åˆ†æï¼š

å¼€å‘æ¨¡å‹-> ç›®çš„ï¼šä½¿ç”¨ç»™å‡ºçš„**æ¯æ—¥ä»·æ ¼æµ**æ¥ç¡®å®šäº¤æ˜“è€…æ¯å¤©**æ˜¯å¦**åº”è¯¥è´­ä¹°ã€æŒæœ‰æˆ–å‡ºå”®å…¶æŠ•èµ„ç»„åˆä¸­çš„èµ„äº§ã€‚

ç»™å‡ºï¼šå®šä»·æ•°æ®æ–‡ä»¶LBMA-GOLD.csvå’ŒBCHAIN-MKPRU.csv

### **è§£é¢˜æ€è·¯**ï¼š

â€‹                   â‘ æ•°æ®åˆå¹¶ï¼ŒæŠŠæ¯”ç‰¹å¸å’Œé»„é‡‘çš„äº¤æ˜“æ•°æ®åˆå¹¶èµ·æ¥ã€‚
â€‹                   â‘¡è®­ç»ƒæ¨¡å‹ï¼Œè¿›è¡Œæ—¶åºé¢„æµ‹ï¼Œå®ç°å½“å¤©æ•°æ®é¢„æµ‹ç¬¬äºŒå¤©æ•°æ®çš„æ—¶åºæ¨¡å‹ã€‚
â€‹                   â‘¢ç”Ÿæˆæ¯æ—¥çš„é¢„æµ‹æ•°æ®ã€‚
â€‹                   â‘£æ„å»ºç›®æ ‡è§„åˆ’æ¨¡å‹ï¼Œæœ€å¤§åŒ–æ¯æ—¥äº¤æ˜“è·åˆ©çš„ç­–ç•¥ã€‚
â€‹                   â‘¤å¯å‘å¼ç®—æ³•æ±‚è§£ã€‚
â€‹                   â‘¥è¿­ä»£äº”å¹´äº¤æ˜“æœŸã€‚
â€‹                   â‘¦çµæ•åº¦åˆ†æã€‚

### æ¨¡å‹ä¸€ï¼š**Prophetæ¨¡å‹**ï¼ˆ2200688.pdfï¼‰

![image-20240128171449883](C:\Users\92579\AppData\Roaming\Typora\typora-user-images\image-20240128171449883.png)

![image-20240128172120541](C:\Users\92579\AppData\Roaming\Typora\typora-user-images\image-20240128172120541.png)

##### å¯ä»¥å¾—åˆ°çš„ï¼š

â‘ æ¨¡å‹æ‹Ÿåˆå›¾ï¼š

![image-20240128172109843](C:\Users\92579\AppData\Roaming\Typora\typora-user-images\image-20240128172109843.png)

â‘¡å‘¨æœŸæ€§ã€è¶‹åŠ¿å›¾ã€‚ã€‚ã€‚

![image-20240128172354659](C:\Users\92579\AppData\Roaming\Typora\typora-user-images\image-20240128172354659.png)

â‘¢è¯„ä¼°æŒ‡æ ‡ï¼š

![image-20240128172721845](C:\Users\92579\AppData\Roaming\Typora\typora-user-images\image-20240128172721845.png)

æ–‡ä¸­é‡‡ç”¨**æ»‘åŠ¨åˆ†æ®µ**è¯„ä¼°ä½¿æ•ˆæœæ›´å¥½

##### æ¨¡å‹ä»£ç ï¼š

```python
import pandas as pd
from prophet import Prophet
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np
import plotly.graph_objects as go
from prophet.plot import plot_plotly, plot_components_plotly

# è¯»å–CSVæ–‡ä»¶
file_path = 'C:/Users/92579/Documents/GitHub/Mathematical-Modeling/å­¦ä¹ è®°å½•/2022ç¾èµ›/Cé¢˜/2022_Problem_C_DATA/BCHAIN-MKPRU.csv'
df = pd.read_csv(file_path)

# è½¬æ¢æ—¥æœŸæ ¼å¼
df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%y')  # ä½¿ç”¨é€‚å½“çš„æ—¥æœŸæ ¼å¼
df.rename(columns={'Date': 'ds', 'Value': 'y'}, inplace=True)

# åˆ›å»ºå¹¶æ‹ŸåˆProphetæ¨¡å‹
m = Prophet()
m.fit(df)

# ç”Ÿæˆæœªæ¥æ—¶é—´ç‚¹
future = m.make_future_dataframe(periods=365)

# è¿›è¡Œé¢„æµ‹
forecast = m.predict(future)

# ç»˜åˆ¶é¢„æµ‹ç»“æœå›¾è¡¨
fig1 = m.plot(forecast)
fig2 = m.plot_components(forecast)

# ä½¿ç”¨Plotlyè¿›è¡Œäº¤äº’å¼å¯è§†åŒ–
fig3 = plot_plotly(m, forecast)
fig4 = plot_components_plotly(m, forecast)

# å®é™…å€¼
y_true = df['y'].values

# é¢„æµ‹å€¼
y_pred = forecast['yhat'].values[-len(y_true):]

# è®¡ç®—å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰
mse = mean_squared_error(y_true, y_pred)

# è®¡ç®—å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰
rmse = np.sqrt(mse)

# è®¡ç®—å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰
mae = mean_absolute_error(y_true, y_pred)

# è®¡ç®—å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®ï¼ˆMAPEï¼‰
mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

# æ‰“å°è¯„ä¼°æŒ‡æ ‡
print(f'Mean Squared Error (MSE): {mse}')
print(f'Root Mean Squared Error (RMSE): {rmse}')
print(f'Mean Absolute Error (MAE): {mae}')
print(f'Mean Absolute Percentage Error (MAPE): {mape}%')

# ç›´æ¥æ˜¾ç¤ºå›¾è¡¨
fig1.show()
input("Press Enter to continue...")

fig2.show()
input("Press Enter to continue...")

fig3.show()
input("Press Enter to continue...")

fig4.show()
input("Press Enter to continue...")
```

è¯¥æ–‡åç»­è¿˜ç»“åˆäº†XGBoostæ¨¡å‹å¯¹æ¨¡å‹è¿›è¡Œä¼˜åŒ–å¤„ç†



### æ¨¡å‹äºŒï¼šARIMAæ¨¡å‹ï¼ˆ2203120.pdfï¼‰

**ä»·æ ¼é¢„æµ‹æ¨¡å‹**

æé«˜é¢„æµ‹ç²¾åº¦ï¼Œç‰¹åˆ«æ˜¯æ—¶é—´åºåˆ—é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œæ˜¯è®¸å¤šé¢†åŸŸå†³ç­–è€…ç»å¸¸é¢ä¸´çš„é‡è¦ä½†å¸¸å¸¸å›°éš¾çš„ä»»åŠ¡ã€‚è‡ªå›å½’ç§¯åˆ†ç§»åŠ¨å¹³å‡ï¼ˆARIMAï¼‰æ¨¡å‹æ˜¯æ—¶é—´åºåˆ—é¢„æµ‹ä¸­æœ€æµè¡Œçš„çº¿æ€§æ¨¡å‹ä¹‹ä¸€ï¼Œè¿‡å»åå¹´æ¥å·²å¹¿æ³›åº”ç”¨äºæ„å»ºæ›´å‡†ç¡®çš„æ··åˆæ¨¡å‹[2]ã€‚ARIMAæ¨¡å‹ç»“åˆäº†ä¸‰ç§åŸºæœ¬æ–¹æ³•ï¼š

- **è‡ªå›å½’ï¼ˆARï¼‰ï¼š** æè¿°å½“å‰å€¼ä¸å†å²å€¼ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶ä½¿ç”¨å˜é‡çš„å†å²æ—¶é—´æ•°æ®æ¥é¢„æµ‹è‡ªèº«ã€‚ARæ¨¡å‹çš„é˜¶æ•°è¢«è®°å½•ä¸ºpå€¼ã€‚å…¶å…¬å¼å¦‚ä¸‹ï¼š
   
- \[ y_t = \alpha_0 + \alpha_1 y_{t-1} + \alpha_2 y_{t-2} + \ldots + \alpha_p y_{t-p} + \varepsilon_t \]_
   
   
å…¶ä¸­ï¼ŒÎ±æ˜¯ç³»æ•°ï¼ŒÎµ_tè¡¨ç¤ºè¯¯å·®ã€‚
   
- **ç§¯åˆ†ï¼ˆIï¼‰ï¼š** å½“æ—¶é—´åºåˆ—å˜å¾—å¹³ç¨³æ—¶ï¼Œéœ€è¦è¿›è¡Œå·®åˆ†ï¼Œå·®åˆ†çš„é˜¶æ•°è¢«è®°å½•ä¸ºdå€¼ã€‚é€šå¸¸ï¼Œä¸€é˜¶å·®åˆ†å°±è¶³å¤Ÿäº†ã€‚

- **ç§»åŠ¨å¹³å‡ï¼ˆMAï¼‰ï¼š** ç§»åŠ¨å¹³å‡æ¨¡å‹ä¾§é‡äºè‡ªå›å½’æ¨¡å‹ä¸­è¯¯å·®é¡¹çš„ç´¯ç§¯ã€‚MAæ¨¡å‹çš„é˜¶æ•°è¢«è®°å½•ä¸ºqå€¼ã€‚å…¶å…¬å¼å¦‚ä¸‹ï¼š
   \[ y_t = c + \varepsilon_t + \theta_1 \varepsilon_{t-1} + \theta_2 \varepsilon_{t-2} + \ldots + \theta_q \varepsilon_{t-q} \]
   å…¶ä¸­ï¼Œcè¡¨ç¤ºå¸¸æ•°é¡¹ï¼ŒÎµ_tæ˜¯æ–¹å·®ä¸ºç™½å™ªå£°è¿‡ç¨‹ï¼ŒÎ¸æ˜¯ç³»æ•°ã€‚

è¯¥æ¨¡å‹è¢«ç§°ä¸ºARIMA(p, d, q)ï¼Œå¦‚å›¾3æ‰€ç¤ºï¼Œå…¶ä¸­pæ˜¯è‡ªå›å½’é¡¹ï¼Œqæ˜¯ç§»åŠ¨å¹³å‡é¡¹ï¼ŒDæ˜¯å·®åˆ†æ¬¡æ•°ã€‚æˆ‘ä»¬å°†æŒ‰ç…§ä¸‹é¢åˆ—å‡ºçš„æ­¥éª¤æ„å»ºå’Œè§£å†³æˆ‘ä»¬çš„æ¨¡å‹ã€‚

**æ­¥éª¤1ï¼šç¨³å®šåŒ–**
ä¸ºäº†ä½¿ç”¨ARIMAæ¨¡å‹ï¼Œæ—¶é—´åºåˆ—å¿…é¡»æ˜¯å¹³ç¨³çš„ã€‚ä½¿ç”¨å¢å¹¿è¿ªåŸº-å¯Œå‹’ï¼ˆAugmented Dickey-Fullerï¼‰å•ä½æ ¹æ£€éªŒæ¥æµ‹è¯•å¹³ç¨³æ€§ã€‚å¦‚æœADFæµ‹è¯•å¾—åˆ°çš„På€¼å°äº0.05ï¼Œåˆ™æ˜¯ä¸€ä¸ªç¨³å®šçš„æ—¶é—´åºåˆ—ã€‚å¦‚æœä¸ç¨³å®šï¼Œå¯ä»¥é€šè¿‡å·®åˆ†æ–¹æ³•å°†éå¹³ç¨³è¿‡ç¨‹è½¬åŒ–ä¸ºå¹³ç¨³è¿‡ç¨‹ã€‚ä»è¡¨2å¯ä»¥çœ‹å‡ºï¼Œç»è¿‡ä¸€é˜¶å·®åˆ†åï¼Œæ—¶é—´åºåˆ—å˜å¾—ç¨³å®šã€‚

**è¡¨2ï¼šå·®åˆ†å‰åé»„é‡‘å’Œæ¯”ç‰¹å¸æ—¶é—´åºåˆ—çš„På€¼**
|        | å·®åˆ†å‰På€¼ | å·®åˆ†åPå€¼ |
| ------ | --------- | --------- |
| é»„é‡‘   | 0.6734    | 0.0043    |
| æ¯”ç‰¹å¸ | 0.9921    | 0.0000    |

**æ­¥éª¤2ï¼šé€‰æ‹©på’Œq**
ä½¿ç”¨è‡ªç›¸å…³å‡½æ•°ï¼ˆACFï¼‰å’Œåè‡ªç›¸å…³å‡½æ•°ï¼ˆPACFï¼‰ç¡®å®špå’Œqçš„å€¼ï¼Œç¡®è®¤æ–¹æ³•å¦‚è¡¨3æ‰€ç¤ºã€‚

**è¡¨3ï¼špå€¼å’Œqå€¼çš„ç¡®è®¤æ–¹æ³•**
| æ¨¡å‹       | ACF       | PACF         |
| ---------- | --------- | ------------ |
| AR(p)      | æˆªå°¾è‡³0   | pé˜¶åæˆªå°¾    |
| MA(q)      | qé˜¶åæˆªå°¾ | æˆªå°¾è‡³0      |
| ARMA(p, q) | qé˜¶åæˆªå°¾ | pé˜¶åæˆªå°¾è‡³0 |
æ³¨ï¼šæˆªå°¾æ„å‘³ç€è½åœ¨ç½®ä¿¡åŒºé—´å†…ï¼ˆ95%çš„ç‚¹ç¬¦åˆè§„åˆ™ï¼‰ã€‚

å›¾4ï¼ˆaï¼‰æ˜¾ç¤ºäº†ä½¿ç”¨2çº§ACFå’Œ1çº§PACFå¯¹é»„é‡‘æ•°æ®è¿›è¡Œæˆªæ–­ï¼Œå›¾4ï¼ˆbï¼‰æ˜¾ç¤ºäº†ä½¿ç”¨2çº§ACFå’Œ2çº§PACFå¯¹æ¯”ç‰¹å¸æ•°æ®è¿›è¡Œæˆªæ–­ã€‚ä»ä¸­æˆ‘ä»¬å¯ä»¥åˆ†åˆ«ç¡®å®špå€¼å’Œqå€¼ã€‚

**æ­¥éª¤3ï¼šç™½å™ªå£°æµ‹è¯•**
å¦‚æœå¾—åˆ°ç™½å™ªå£°ï¼Œæ„å‘³ç€æ—¶é—´åºåˆ—ä¸­çš„æœ‰ç”¨ä¿¡æ¯å·²ç»è¢«æå–å‡ºæ¥ï¼Œå‰©ä¸‹çš„éƒ½æ˜¯éšæœºæ‰°åŠ¨ï¼Œä¸èƒ½è¢«é¢„æµ‹å’Œåˆ©ç”¨ã€‚å¦‚æœæ®‹å·®åºåˆ—é€šè¿‡äº†ç™½å™ªå£°æµ‹è¯•ï¼Œå»ºæ¨¡å¯ä»¥ç»ˆæ­¢ï¼Œå› ä¸ºæ²¡æœ‰ä¿¡æ¯å¯ç»§ç»­æå–ã€‚

é»„é‡‘çš„ARIMAæ¨¡å‹ä¸ºARIMA(2,1,1)ï¼Œæ¯”ç‰¹å¸ä¸ºARIMA(2,1,2)ã€‚è¯¥æ¨¡å‹çš„ç™½å™ªå£°æµ‹è¯•è¾“å‡ºçš„på€¼éå¸¸æ¥è¿‘0ï¼Œè¯´æ˜å®ƒéµå¾ªå‡å€¼ä¸º0çš„æ­£æ€åˆ†å¸ƒï¼Œå³æ˜¯ä¸€ä¸ªç™½å™ªå£°ã€‚

**æ­¥éª¤4ï¼šé¢„æµ‹**
ä¸ºäº†åŠæ—¶å‡†ç¡®åœ°é¢„æµ‹æœªæ¥å¸‚åœºï¼Œæˆ‘ä»¬å°†è¿ç»­30å¤©çš„æ•°æ®ä½œä¸ºè®­ç»ƒé›†ï¼Œæ¥ä¸‹æ¥3å¤©çš„æ•°æ®ä½œä¸ºæµ‹è¯•é›†ã€‚è®­ç»ƒé›†çš„ç§»åŠ¨æ­¥é•¿ä¸º3ã€‚ä¸€ä¸ªå‘¨æœŸçš„é¢„æµ‹ç»“æœå¦‚å›¾5æ‰€ç¤ºã€‚é»„é‡‘çš„ç›¸å…³ç³»æ•°RÂ²ä¸º0.8592ï¼Œæ¯”ç‰¹å¸ä¸º0.9304ã€‚è¯¥æ¨¡å‹çš„é¢„æµ‹ç»“æœç›¸å¯¹æˆåŠŸï¼Œå¯ç”¨äºå®é™…åº”ç”¨ã€‚

##### å¯ä»¥å¾—åˆ°çš„ï¼š![image-20240128174343275](C:\Users\92579\AppData\Roaming\Typora\typora-user-images\image-20240128174343275.png)

![image-20240128174425626](C:\Users\92579\AppData\Roaming\Typora\typora-user-images\image-20240128174425626.png)

![image-20240128174438915](C:\Users\92579\AppData\Roaming\Typora\typora-user-images\image-20240128174438915.png)

![image-20240128174450436](C:\Users\92579\AppData\Roaming\Typora\typora-user-images\image-20240128174450436.png)

##### æ¨¡å‹ä»£ç ï¼š

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.stattools import adfuller

# è¯»å–CSVæ–‡ä»¶
file_path = "C:/Users/92579/Documents/GitHub/Mathematical-Modeling/å­¦ä¹ è®°å½•/2022ç¾èµ›/Cé¢˜/2022_Problem_C_DATA/BCHAIN-MKPRU.csv"
df = pd.read_csv(file_path, parse_dates=['Date'], index_col='Date')

# æ•°æ®é¢„å¤„ç†
df = df.dropna()  # åˆ é™¤ç¼ºå¤±å€¼
df = df.resample('D').mean()  # å°†æ•°æ®æŒ‰å¤©é‡é‡‡æ ·ï¼Œå–å‡å€¼

# å¯è§†åŒ–æ•°æ®
plt.figure(figsize=(10, 6))
plt.plot(df['Value'])
plt.title('Bitcoin Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price')
plt.show()

# è¿›è¡Œç¨³å®šæ€§æ£€éªŒï¼ˆAugmented Dickey-Fuller Testï¼‰
result_adf = adfuller(df['Value'])
print(f'ADF Statistic: {result_adf[0]}')
print(f'p-value: {result_adf[1]}')

# å¦‚æœæ—¶é—´åºåˆ—ä¸ç¨³å®šï¼Œè¿›è¡Œå·®åˆ†æ“ä½œ
if result_adf[1] > 0.05:
    df['Value'] = df['Value'].diff()
    df = df.dropna()

# å†æ¬¡è¿›è¡Œå¯è§†åŒ–
plt.figure(figsize=(10, 6))
plt.plot(df['Value'])
plt.title('Differenced Bitcoin Price Over Time')
plt.xlabel('Date')
plt.ylabel('Price Difference')
plt.show()

# æ ¹æ®ACFå’ŒPACFå›¾ç¡®å®špå’Œqçš„å€¼
plot_acf(df['Value'], lags=20)
plt.show()
plot_pacf(df['Value'], lags=20)
plt.show()

# æ ¹æ®ACFå’ŒPACFå›¾ç¡®å®špå’Œqçš„å€¼
p = 2  # æ ¹æ®å›¾ç¤ºç¡®å®š
d = 1  # ä¸€é˜¶å·®åˆ†
q = 1  # æ ¹æ®å›¾ç¤ºç¡®å®š

# æ‹ŸåˆARIMAæ¨¡å‹
model = ARIMA(df['Value'], order=(p, d, q))
result = model.fit()

# æ‰“å°æ¨¡å‹çš„å‚æ•°
print(result.summary())

# è¿›è¡Œç™½å™ªå£°æ£€éªŒ
residuals = result.resid
fig, ax = plt.subplots(1, 2, figsize=(12, 4))
plot_acf(residuals, ax=ax[0])
plot_pacf(residuals, ax=ax[1])
plt.show()

# è¿›è¡Œæ¨¡å‹è¯„ä¼°å’Œé¢„æµ‹
future_days = 3  # è®¾ç½®é¢„æµ‹æœªæ¥å‡ å¤©çš„æ•°æ®
forecast = result.forecast(steps=future_days)

# æ‰“å°é¢„æµ‹ç»“æœ
print("Forecasted Values:")
print(forecast)

# å¯è§†åŒ–é¢„æµ‹ç»“æœ
plt.figure(figsize=(10, 6))
plt.plot(df['Value'], label='Historical Data')
plt.plot(pd.date_range(df.index[-1], periods=future_days + 1)[1:], forecast, label='Forecast', color='red')
plt.title('Bitcoin Price Prediction')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.show()
```





### æ¨¡å‹ä¸‰ï¼šLSTMæ¨¡å‹ï¼ˆ2204883.pdfï¼‰

1. **LSTMç®€ä»‹ï¼š**
   - LSTMï¼ˆé•¿çŸ­æ—¶è®°å¿†ç½‘ç»œï¼‰æ˜¯å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰çš„ä¸€ç§ç‰¹æ®Šç±»å‹ï¼Œè§£å†³äº†åœ¨RNNé•¿åºåˆ—è®­ç»ƒä¸­å‡ºç°çš„æ¢¯åº¦çˆ†ç‚¸å’Œæ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚å½“ç½‘ç»œçš„å±‚æ•°å¢åŠ æ—¶ï¼Œåç»­èŠ‚ç‚¹å¯¹å…ˆå‰èŠ‚ç‚¹çš„æ„ŸçŸ¥å‡å¼±ï¼Œéšç€æ—¶é—´çš„æ¨ç§»é—å¿˜å…ˆå‰ä¿¡æ¯çš„ç°è±¡é€æ¸å‘ç”Ÿã€‚
   - LSTMé€šè¿‡åœ¨éšè—å±‚çš„æ¯ä¸ªç¥ç»å•å…ƒä¸­æ·»åŠ ä¸€ä¸ªå†…å­˜å•å…ƒæ¥æ”¹è¿›RNNï¼Œç§°ä¸ºâ€œç»†èƒçŠ¶æ€â€ï¼Œå¹¶ä½¿ç”¨é—å¿˜é—¨ã€è¾“å…¥é—¨å’Œè¾“å‡ºé—¨ç­‰ç»“æ„æ¥æ§åˆ¶æ—¶é—´åºåˆ—ä¸Šçš„å†…å­˜ä¿¡æ¯ã€‚è¿™ä½¿å¾—LSTMèƒ½å¤Ÿæ›´æ·±å…¥åœ°æŒ–æ˜æ•°æ®ä¹‹é—´çš„æ½œåœ¨æ¨¡å¼ï¼Œä»è€Œä½¿é¢„æµ‹æ›´å‡†ç¡®å¯é ã€‚

2. **LSTMçš„é—¨ç»“æ„ï¼š**
   - **é—å¿˜é—¨ï¼š** é€‰æ‹©æ€§åœ°é—å¿˜è¿‡å»çš„æŸäº›ä¿¡æ¯ã€‚ä½¿ç”¨Sigmoidå‡½æ•°æ¥å®ç°ï¼Œè¾“å‡ºå€¼åœ¨0å’Œ1ä¹‹é—´ï¼Œè¡¨ç¤ºæ˜¯å¦åº”è¯¥é—å¿˜å…ˆå‰çš„ä¿¡æ¯ã€‚
   - **è¾“å…¥é—¨ï¼š** é€‰æ‹©æ€§åœ°è®°ä½è¿‡å»çš„æŸäº›ä¿¡æ¯å¹¶ç¡®å®šå½“å‰è®°å¿†å•å…ƒçš„å€¼ã€‚ç”Ÿæˆä¸¤ä¸ªä¸­é—´å˜é‡ï¼Œå…¶ä¸­ä¸€ä¸ªç”¨äºè¾“å…¥é—¨çš„è¾“å‡ºå€¼ï¼Œå¦ä¸€ä¸ªç”¨äºå€™é€‰è®°å¿†å•å…ƒå€¼ã€‚
   - **è¾“å‡ºé—¨ï¼š** é€‰æ‹©æ€§åœ°ç”Ÿæˆå½“å‰éšè—çŠ¶æ€çš„å€¼ã€‚è¾“å‡ºå€¼ç”¨ä½œä¸­é—´å˜é‡ï¼Œé€šè¿‡å¯¹å½“å‰è®°å¿†å•å…ƒå€¼è¿›è¡Œå¤„ç†ç”Ÿæˆéšè—çŠ¶æ€å€¼ã€‚

3. **Sliding Window Algorithmï¼ˆæ»‘åŠ¨çª—å£ç®—æ³•ï¼‰ï¼š**
   - åœ¨é¢„æµ‹æ¯å¤©çš„é»„é‡‘å’Œæ¯”ç‰¹å¸ä»·æ ¼æ—¶ï¼Œä½¿ç”¨æ»‘åŠ¨çª—å£ç®—æ³•ã€‚ä»…ä½¿ç”¨å‰ä¸€å¤©çš„ä»·æ ¼æ•°æ®ä½œä¸ºLSTMæ¨¡å‹çš„è¾“å…¥ï¼Œæ»‘åŠ¨çª—å£åŒ…å«å½“å‰å¤©å’Œå…¶å‰då¤©çš„æ•°æ®ï¼Œç”¨äºè®­ç»ƒæ¨¡å‹ã€‚

4. **è°ƒæ•´å‚æ•°ï¼š**
   - é€šè¿‡è°ƒæ•´éšè—å±‚å¤§å°lã€æ»‘åŠ¨çª—å£å¤§å°dã€è®­ç»ƒæ»‘åŠ¨çª—å£å¤§å°d0ã€å­¦ä¹ ç‡Î»å’Œè¿­ä»£æ¬¡æ•°Îµç­‰5ä¸ªå‚æ•°ï¼Œä½¿ç”¨MAPEï¼ˆå¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®ï¼‰è¯„ä¼°é»„é‡‘ä»·æ ¼é¢„æµ‹ç»“æœã€‚
   - åœ¨è°ƒæ•´å‚æ•°æ—¶ï¼Œæ¯æ¬¡åªæ›´æ”¹ä¸€ä¸ªå‚æ•°çš„å€¼ï¼Œä¿æŒå…¶ä»–å‚æ•°ä¸å˜ã€‚é€‰æ‹©MAPEå€¼æœ€å°çš„å‚æ•°ç»„åˆä½œä¸ºæœ€ç»ˆçš„é»„é‡‘å’Œæ¯”ç‰¹å¸ä»·æ ¼é¢„æµ‹ç»“æœã€‚

5. **ç»“æœå±•ç¤ºï¼š**
   - æœ€ç»ˆé€‰æ‹©çš„å‚æ•°ç»„åˆä¸º[ğ‘™=100, ğ‘‘=10, ğ‘‘0=5, ğœ†=0.001, ğœ–=50]ï¼Œå¯¹åº”çš„MAPEå€¼ä¸º0.007261552ã€‚é€šè¿‡æ¯”è¾ƒé¢„æµ‹æ›²çº¿å’ŒçœŸå®æ›²çº¿ï¼Œè¯æ˜äº†å¯¹é»„é‡‘å’Œæ¯”ç‰¹å¸ä»·æ ¼çš„é¢„æµ‹æ•ˆæœè‰¯å¥½ã€‚

##### å¯ä»¥å¾—åˆ°çš„ï¼š

![image-20240128182208870](C:\Users\92579\AppData\Roaming\Typora\typora-user-images\image-20240128182208870.png)

Train Score: 469.53 RMSE 
Test Score: 8900.69 RMSE

![image-20240128184121309](C:\Users\92579\AppData\Roaming\Typora\typora-user-images\image-20240128184121309.png)

##### æ¨¡å‹ä»£ç ï¼š

```python
# å¯¼å…¥å¿…è¦çš„åº“
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import LSTM, Dense

# è¯»å–CSVæ–‡ä»¶
file_path = "C:/Users/92579/Documents/GitHub/Mathematical-Modeling/å­¦ä¹ è®°å½•/2022ç¾èµ›/Cé¢˜/2022_Problem_C_DATA/BCHAIN-MKPRU.csv"
df = pd.read_csv(file_path, parse_dates=['Date'], index_col='Date')

# æ•°æ®é¢„å¤„ç†
df = df.dropna()  # åˆ é™¤ç¼ºå¤±å€¼
df = df.resample('D').mean()  # å°†æ•°æ®æŒ‰å¤©é‡é‡‡æ ·ï¼Œå–å‡å€¼

# å½’ä¸€åŒ–æ•°æ®
scaler = MinMaxScaler()
df['Value'] = scaler.fit_transform(df[['Value']])

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
train_size = int(len(df) * 0.8)
train, test = df[:train_size], df[train_size:]

# åˆ›å»ºçª—å£æ•°æ®é›†
def create_dataset(dataset, look_back=1):
    dataX, dataY = [], []
    for i in range(len(dataset) - look_back):
        a = dataset[i:(i + look_back), 0]
        dataX.append(a)
        dataY.append(dataset[i + look_back, 0])
    return np.array(dataX), np.array(dataY)

look_back = 10  # å¯è°ƒæ•´çª—å£å¤§å°
trainX, trainY = create_dataset(np.array(train), look_back)
testX, testY = create_dataset(np.array(test), look_back)

# è°ƒæ•´è¾“å…¥æ•°æ®çš„å½¢çŠ¶
trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))

# æ„å»ºLSTMæ¨¡å‹
model = Sequential()
model.add(LSTM(50, input_shape=(1, look_back)))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')

# è®­ç»ƒæ¨¡å‹
model.fit(trainX, trainY, epochs=50, batch_size=1, verbose=2)

# åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹
trainPredict = model.predict(trainX)
testPredict = model.predict(testX)

# åå½’ä¸€åŒ–é¢„æµ‹å€¼
trainPredict = scaler.inverse_transform(trainPredict)
trainY = scaler.inverse_transform([trainY])
testPredict = scaler.inverse_transform(testPredict)
testY = scaler.inverse_transform([testY])

# è®¡ç®—è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å‡æ–¹æ ¹è¯¯å·®
trainScore = np.sqrt(np.mean(np.square(trainY[0] - trainPredict[:, 0])))
testScore = np.sqrt(np.mean(np.square(testY[0] - testPredict[:, 0])))

print('Train Score: %.2f RMSE' % (trainScore))
print('Test Score: %.2f RMSE' % (testScore))

# å¯è§†åŒ–è®­ç»ƒé›†çš„é¢„æµ‹ç»“æœ
trainPredictPlot = np.empty_like(df)
trainPredictPlot[:, :] = np.nan
trainPredictPlot[look_back:len(trainPredict) + look_back, :] = trainPredict

# å¯è§†åŒ–æµ‹è¯•é›†çš„é¢„æµ‹ç»“æœ
testPredictPlot = np.empty_like(df)
testPredictPlot[:, :] = np.nan
testPredictPlot[len(trainPredict) + (look_back * 2):len(df), :] = testPredict

# å°†åŸå§‹æ•°æ®ã€è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„é¢„æµ‹ç»“æœè¿›è¡Œå¯è§†åŒ–
plt.figure(figsize=(10, 6))
plt.plot(scaler.inverse_transform(df[['Value']]), label='Original Data')
plt.plot(trainPredictPlot, label='Train Predictions')
plt.plot(testPredictPlot, label='Test Predictions')
plt.title('Bitcoin Price Prediction using LSTM')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.show()

```

### 